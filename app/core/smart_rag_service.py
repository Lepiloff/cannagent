import logging
from typing import List, Optional, Dict, Any
from app.models.session import ConversationSession
from app.models.schemas import ChatResponse, CompactStrain, CompactFeeling, CompactHelpsWith, CompactNegative, CompactFlavor, Strain
from app.core.smart_query_analyzer import SmartQueryAnalyzer, SmartAnalysis
from app.core.context_provider import ContextProvider
from app.core.universal_action_executor import UniversalActionExecutor
from app.core.session_manager import get_session_manager
from app.db.repository import StrainRepository
from app.core.llm_interface import get_llm
from app.core.intent_detection import IntentType
from app.core.dialog_policy import extract_request_signals, decide_action_hint, detect_language
import os

logger = logging.getLogger(__name__)


class SmartRAGService:
    """
    Smart RAG Service v3.0 - –ò–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã–π —Å–µ—Ä–≤–∏—Å —Å AI-driven –æ–±—Ä–∞–±–æ—Ç–∫–æ–π –∑–∞–ø—Ä–æ—Å–æ–≤
    
    –û—Å–Ω–æ–≤–Ω—ã–µ –ø—Ä–∏–Ω—Ü–∏–ø—ã:
    - AI –æ–ø—Ä–µ–¥–µ–ª—è–µ—Ç –ø–ª–∞–Ω –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –∑–∞–ø—Ä–æ—Å–∞
    - –ú–∏–Ω–∏–º—É–º —Ö–∞—Ä–¥–∫–æ–¥–∞, –º–∞–∫—Å–∏–º—É–º AI —Ä–∞—Å—Å—É–∂–¥–µ–Ω–∏–π
    - –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–æ–µ –∏—Å–∫–ª—é—á–µ–Ω–∏–µ invalid –¥–∞–Ω–Ω—ã—Ö
    - –ü–æ–ª–Ω—ã–π –∫–æ–Ω—Ç–µ–∫—Å—Ç –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π
    """
    
    def __init__(self, repository: StrainRepository):
        self.repository = repository
        self.session_manager = get_session_manager()
        
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–æ–≤ v3.0
        self.llm_interface = get_llm()
        self.smart_analyzer = SmartQueryAnalyzer(self.llm_interface)
        self.context_provider = ContextProvider(repository)
        self.action_executor = UniversalActionExecutor(repository)
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤–∫–ª—é—á–µ–Ω–∏—è Smart Query Executor
        self.use_smart_executor = os.getenv('USE_SMART_EXECUTOR', 'true').lower() == 'true'
        
        if not self.use_smart_executor:
            logger.warning("Smart Query Executor disabled, falling back to legacy mode")
    
    def process_contextual_query(
        self,
        query: str,
        session_id: Optional[str] = None,
        history: Optional[List[str]] = None,
        source_platform: Optional[str] = None
    ) -> ChatResponse:
        """
        –ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∑–∞–ø—Ä–æ—Å–æ–≤ —Å Smart Query Executor v3.0
        """
        
        logger.info(f"Processing query with Smart RAG v3.0: {query[:50]}...")
        
        # 1. –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–µ–π
        session = self.session_manager.get_or_restore_session(session_id)
        
        # 2. –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏—è Smart Executor
        if not self.use_smart_executor:
            # Fallback –∫ legacy –æ–±—Ä–∞–±–æ—Ç–∫–µ
            return self._legacy_process_query(query, session)
        
        # 3. –ü–æ–ª—É—á–µ–Ω–∏–µ –ø–æ–ª–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        full_context = self.context_provider.get_full_context(query, session)
        session_strains = self.context_provider.get_session_strains(session)
        
        # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö –∫–æ–º–∞–Ω–¥ (reset)
        if self._is_reset_command(query):
            return self._handle_reset(session, query)
        
        # 5. –ü–æ–¥—Å–∫–∞–∑–∫–∏ –ø–æ–ª–∏—Ç–∏–∫–∏ –¥–∏–∞–ª–æ–≥–∞ (–∫–∞—Ç–µ–≥–æ—Ä–∏—è/—ç—Ñ—Ñ–µ–∫—Ç—ã/–≤–∫—É—Å—ã/—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫–∞)
        policy_signals = extract_request_signals(query)
        policy_hint = decide_action_hint(session, session_strains, policy_signals)

        # 6. Smart –∞–Ω–∞–ª–∏–∑ –∑–∞–ø—Ä–æ—Å–∞ —Å –ø–æ–ª–Ω—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º + policy
        try:
            smart_analysis = self.smart_analyzer.analyze_query(
                query, session, session_strains, full_context, policy_hint
            )
            logger.info(f"Smart analysis: {smart_analysis.action_plan.primary_action}, confidence: {smart_analysis.confidence}")
        except Exception as e:
            logger.error(f"Smart analysis failed: {e}")
            # Fallback –∫ legacy –æ–±—Ä–∞–±–æ—Ç–∫–µ
            return self._legacy_process_query(query, session)
        
        # 7. –ï—Å–ª–∏ –ø–æ–ª–∏—Ç–∏–∫–∞ —Ç—Ä–µ–±—É–µ—Ç —Ä–∞—Å—à–∏—Ä–∏—Ç—å –ø–æ–∏—Å–∫ (–Ω–æ–≤–∞—è –∫–∞—Ç–µ–≥–æ—Ä–∏—è/—ç—Ñ—Ñ–µ–∫—Ç—ã, –∫–æ–Ω—Ç–µ–∫—Å—Ç –ø–ª–æ—Ö–æ —Å–æ–≤–ø–∞–¥–∞–µ—Ç)
        if policy_hint.get("force_expand_search") and smart_analysis.action_plan.primary_action not in ["search_strains", "expand_search"]:
            logger.info("Dialog policy forces expand_search due to mismatch with session context")
            smart_analysis.action_plan.primary_action = "expand_search"

        # –í–ª–∏–≤–∞–µ–º –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã/—Å–æ—Ä—Ç–∏—Ä–æ–≤–∫—É –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã (–±–µ–∑ –ø–µ—Ä–µ–∑–∞–ø–∏—Å–∏ —É–∂–µ –∑–∞–¥–∞–Ω–Ω—ã—Ö AI)
        if policy_hint.get("suggested_filters"):
            params_filters = smart_analysis.action_plan.parameters.setdefault("filters", {})
            for k, v in policy_hint["suggested_filters"].items():
                params_filters.setdefault(k, v)
        if policy_hint.get("suggested_sort") and "sort" not in smart_analysis.action_plan.parameters:
            smart_analysis.action_plan.parameters["sort"] = policy_hint["suggested_sort"]

        # –Ø–∑—ã–∫: –µ—Å–ª–∏ AI –Ω–µ —É–∫–∞–∑–∞–ª, –∏—Å–ø–æ–ª—å–∑—É–µ–º –¥–µ—Ç–µ–∫—Ü–∏—é –ø–æ–ª–∏—Ç–∏–∫–∏
        if not smart_analysis.detected_language:
            smart_analysis.detected_language = policy_hint.get("language") or 'en'

        # 8. –û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–ª—É—á–∞–µ–≤ –Ω–µ–¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        if smart_analysis.action_plan.primary_action in ['sort_strains', 'filter_strains', 'select_strains'] and not session_strains:
            # –ï—Å–ª–∏ –ø—ã—Ç–∞–µ–º—Å—è —Å–æ—Ä—Ç–∏—Ä–æ–≤–∞—Ç—å/—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞—Ç—å/–≤—ã–±–∏—Ä–∞—Ç—å, –Ω–æ –Ω–µ—Ç —Å–æ—Ä—Ç–æ–≤ –≤ —Å–µ—Å—Å–∏–∏ - –¥–µ–ª–∞–µ–º –ø–æ–∏—Å–∫
            logger.info(f"Converting {smart_analysis.action_plan.primary_action} to search_strains due to empty session")
            smart_analysis.action_plan.primary_action = 'search_strains'
        elif smart_analysis.action_plan.primary_action in ['expand_search'] and not session_strains:
            # –î–ª—è expand_search –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ - –ø—Ä–æ—Å—Ç–æ –≤—ã–ø–æ–ª–Ω—è–µ–º –ø–æ–∏—Å–∫
            pass
        
        # 9. –í—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –¥–µ–π—Å—Ç–≤–∏—è –ø–æ AI –ø–ª–∞–Ω—É
        result_strains = self.action_executor.execute_action(
            smart_analysis.action_plan,
            session_strains
        )
        
        # 10. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏
        self._update_session(session, query, smart_analysis, result_strains)
        
        # 11. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏
        self.session_manager.save_session_with_backup(session)
        
        # 12. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        return self._build_smart_response(smart_analysis, result_strains, session)
    
    def _handle_reset(self, session: ConversationSession, query: str) -> ChatResponse:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã —Å–±—Ä–æ—Å–∞"""
        
        logger.info("Handling reset command")
        
        # –û—á–∏—Å—Ç–∫–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ —Å–µ—Å—Å–∏–∏
        session.recommended_strains_history = []
        session.conversation_history = []
        session.current_topic = None
        session.previous_topics = []
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞ –¥–ª—è –æ—Ç–≤–µ—Ç–∞
        language = detect_language(query)
        
        responses = {
            'es': "Perfecto, empecemos de nuevo. ¬øQu√© tipo de efectos buscas?",
            'en': "Perfect, let's start fresh. What kind of effects are you looking for?"
        }
        
        quick_actions = self._get_new_search_suggestions(language)
        
        return ChatResponse(
            response=responses.get(language, responses['es']),
            recommended_strains=[],
            detected_intent='reset',
            filters_applied={},
            session_id=session.session_id,
            query_type='reset',
            language=language,
            confidence=1.0,
            quick_actions=quick_actions,
            is_restored=session.is_restored,
            is_fallback=False
        )
    
    def _handle_no_context(self, analysis: SmartAnalysis, session: ConversationSession) -> ChatResponse:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–ø—Ä–æ—Å–æ–≤ –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        
        logger.info("Handling no context situation")
        
        responses = {
            'es': "No tengo variedades anteriores para comparar. ¬øQu√© efectos buscas?",
            'en': "I don't have previous strains to compare. What effects are you looking for?"
        }
        
        quick_actions = self._get_new_search_suggestions(analysis.detected_language)
        
        return ChatResponse(
            response=responses.get(analysis.detected_language, responses['es']),
            recommended_strains=[],
            detected_intent='no_context',
            filters_applied={},
            session_id=session.session_id,
            query_type='clarification',
            language=analysis.detected_language,
            confidence=1.0,
            quick_actions=quick_actions,
            is_restored=session.is_restored,
            is_fallback=analysis.is_fallback
        )
    
    def _build_smart_response(
        self,
        analysis: SmartAnalysis,
        strains: List[Strain],
        session: ConversationSession
    ) -> ChatResponse:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ Smart –∞–Ω–∞–ª–∏–∑–∞"""
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –≥–æ—Ç–æ–≤—ã–π natural response –æ—Ç AI —Å –ø–æ–¥—Å—Ç–∞–Ω–æ–≤–∫–æ–π —Ä–µ–∞–ª—å–Ω—ã—Ö –Ω–∞–∑–≤–∞–Ω–∏–π
        response_text = self._substitute_strain_placeholders(analysis.natural_response, strains)
        
        # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–µ —Å–æ—Ä—Ç–∞ –¥–ª—è UI
        compact_strains = self._build_compact_strains(strains)
        
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ quick actions (–ª–∏–±–æ –æ—Ç AI, –ª–∏–±–æ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ)
        quick_actions = analysis.suggested_follow_ups or self._generate_contextual_actions(
            strains, analysis.detected_language, session
        )
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ AI reasoning (–æ–ø—Ü–∏–æ–Ω–∞–ª—å–Ω–æ –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏)
        if os.getenv('ENABLE_AI_REASONING_DEBUG', 'false').lower() == 'true':
            response_text += f"\n\nü§ñ Reasoning: {analysis.action_plan.reasoning}"
        
        return ChatResponse(
            response=response_text,
            recommended_strains=compact_strains,
            detected_intent=analysis.action_plan.primary_action,
            filters_applied=analysis.action_plan.parameters,
            session_id=session.session_id,
            query_type=analysis.action_plan.primary_action,
            language=analysis.detected_language,
            confidence=analysis.confidence,
            quick_actions=quick_actions,
            is_restored=session.is_restored,
            is_fallback=analysis.is_fallback,
            warnings=[] if analysis.confidence > 0.7 else ["Low confidence analysis"]
        )
    
    def _update_session(
        self,
        session: ConversationSession,
        query: str,
        analysis: SmartAnalysis,
        strains: List[Strain]
    ):
        """–û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏ –ø–æ—Å–ª–µ smart –æ–±—Ä–∞–±–æ—Ç–∫–∏"""
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —è–∑—ã–∫–∞
        if analysis.detected_language:
            session.detected_language = analysis.detected_language
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ —Å–æ—Ä—Ç–æ–≤ –≤ –∏—Å—Ç–æ—Ä–∏—é
        if strains:
            strain_ids = [s.id for s in strains]
            session.add_strain_recommendation(strain_ids)
            logger.info(f"Added {len(strain_ids)} strains to session history")
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Ç–µ–º—ã —Ä–∞–∑–≥–æ–≤–æ—Ä–∞ (–ø–æ–ø—ã—Ç–∫–∞ –æ–ø—Ä–µ–¥–µ–ª–∏—Ç—å –ø–æ –¥–µ–π—Å—Ç–≤–∏—é)
        if analysis.action_plan.primary_action == 'expand_search':
            # –ù–æ–≤—ã–π –ø–æ–∏—Å–∫ - –≤–æ–∑–º–æ–∂–Ω–æ —Å–º–µ–Ω–∞ —Ç–µ–º—ã
            if 'sleep' in query.lower() or 'dormir' in query.lower():
                session.update_topic(IntentType.SLEEP)
            elif 'energy' in query.lower() or 'energ√≠a' in query.lower():
                session.update_topic(IntentType.ENERGY)
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π (–µ—Å–ª–∏ –µ—Å—Ç—å –≤ –ø–∞—Ä–∞–º–µ—Ç—Ä–∞—Ö –¥–µ–π—Å—Ç–≤–∏—è)
        if 'criteria' in analysis.action_plan.parameters:
            criteria = analysis.action_plan.parameters['criteria']
            if isinstance(criteria, dict) and 'effects' in criteria:
                if 'desired' in criteria['effects']:
                    session.update_preferences('preferred_effects', criteria['effects']['desired'])
        
        # –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –∑–∞–ø–∏—Å–∏ –≤ –∏—Å—Ç–æ—Ä–∏—é —Ä–∞–∑–≥–æ–≤–æ—Ä–∞
        session.add_conversation_entry(
            query=query,
            response=analysis.natural_response,
            intent=session.current_topic
        )
        
        # –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ –≤—Ä–µ–º–µ–Ω–∏ –∞–∫—Ç–∏–≤–Ω–æ—Å—Ç–∏
        session.update_activity()
    
    def _build_compact_strains(self, strains: List[Strain]) -> List[CompactStrain]:
        """–°–æ–∑–¥–∞–Ω–∏–µ –∫–æ–º–ø–∞–∫—Ç–Ω—ã—Ö –æ–±—ä–µ–∫—Ç–æ–≤ —Å–æ—Ä—Ç–æ–≤ –¥–ª—è UI"""
        
        compact_strains = []
        for strain in strains:
            # –û—á–∏—Å—Ç–∫–∞ –∏–º–µ–Ω–∏
            clean_name = strain.name.split(' | ')[0] if strain.name else strain.name
            
            compact_strain = CompactStrain(
                id=strain.id,
                name=clean_name,
                cbd=strain.cbd,
                thc=strain.thc,
                cbg=strain.cbg,
                category=strain.category,
                slug=strain.slug,
                url=self._build_strain_url(strain.slug),
                feelings=[CompactFeeling(name=f.name) for f in strain.feelings] if strain.feelings else [],
                helps_with=[CompactHelpsWith(name=h.name) for h in strain.helps_with] if strain.helps_with else [],
                negatives=[CompactNegative(name=n.name) for n in strain.negatives] if strain.negatives else [],
                flavors=[CompactFlavor(name=fl.name) for fl in strain.flavors] if strain.flavors else []
            )
            compact_strains.append(compact_strain)
        
        return compact_strains
    
    def _substitute_strain_placeholders(self, response_text: str, strains: List[Strain]) -> str:
        """–ó–∞–º–µ–Ω—è–µ—Ç –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã [strain_name], [Strain Name] –Ω–∞ —Ä–µ–∞–ª—å–Ω—ã–µ –Ω–∞–∑–≤–∞–Ω–∏—è —Å–æ—Ä—Ç–æ–≤"""
        
        if not strains or not response_text:
            return response_text
        
        # –ü–æ–ª—É—á–∞–µ–º –ø–µ—Ä–≤—ã–π —Å–æ—Ä—Ç –∫–∞–∫ –æ—Å–Ω–æ–≤–Ω–æ–π –¥–ª—è –∑–∞–º–µ–Ω—ã
        primary_strain = strains[0]
        primary_name = primary_strain.name.split(' | ')[0] if primary_strain.name else "Unknown"
        
        # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä–æ–≤ –¥–ª—è –∑–∞–º–µ–Ω—ã
        placeholders = [
            "[strain_name]", "[Strain Name]", "[strain name]", "[STRAIN_NAME]",
            "[nombre de la cepa]", "[Nombre de la Cepa]", "[NOMBRE DE LA CEPA]",
            "[cepa]", "[Cepa]", "[CEPA]", "[variety]", "[Variety]", "[VARIETY]",
            "Nombre de la variedad", "'Nombre de la variedad'", "[Nombre de la variedad]",
            "nombre de la variedad", "'nombre de la variedad'", "[nombre de la variedad]",
            "Strain Name", "'Strain Name'", "strain name", "'strain name'"
        ]
        
        result_text = response_text
        
        # –ó–∞–º–µ–Ω—è–µ–º –≤—Å–µ –ø–ª–µ–π—Å—Ö–æ–ª–¥–µ—Ä—ã –Ω–∞ –Ω–∞–∑–≤–∞–Ω–∏–µ –ø–µ—Ä–≤–æ–≥–æ —Å–æ—Ä—Ç–∞
        for placeholder in placeholders:
            result_text = result_text.replace(placeholder, primary_name)
        
        # –ï—Å–ª–∏ –µ—Å—Ç—å –Ω–µ—Å–∫–æ–ª—å–∫–æ —Å–æ—Ä—Ç–æ–≤, –¥–æ–±–∞–≤–ª—è–µ–º –∏—Ö —á–µ—Ä–µ–∑ –∑–∞–ø—è—Ç—É—é –¥–ª—è –Ω–µ–∫–æ—Ç–æ—Ä—ã—Ö —Å–ª—É—á–∞–µ–≤
        if len(strains) > 1:
            # –ò—â–µ–º –∫–æ–Ω—Å—Ç—Ä—É–∫—Ü–∏–∏ —Ç–∏–ø–∞ "cepas como [strain_name]" –∏ –∑–∞–º–µ–Ω—è–µ–º –Ω–∞ —Å–ø–∏—Å–æ–∫
            strain_names = [s.name.split(' | ')[0] for s in strains[:3]]  # –ü–µ—Ä–≤—ã–µ 3 —Å–æ—Ä—Ç–∞
            strain_list = ", ".join(strain_names)
            
            # –ü–∞—Ç—Ç–µ—Ä–Ω—ã –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —á–∏—Å–ª–∞
            multiple_patterns = [
                f"cepas como {primary_name}",
                f"strains like {primary_name}", 
                f"variedades como {primary_name}",
                f"varieties like {primary_name}"
            ]
            
            for pattern in multiple_patterns:
                if pattern in result_text:
                    replacement = pattern.replace(primary_name, strain_list)
                    result_text = result_text.replace(pattern, replacement)
        
        return result_text
    
    def _build_strain_url(self, strain_slug: str) -> Optional[str]:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ URL –¥–ª—è —Å–æ—Ä—Ç–∞"""
        if not strain_slug:
            return None
        base_url = os.getenv('CANNAMENTE_BASE_URL')
        url_pattern = os.getenv('STRAIN_URL_PATTERN', '/strain/{slug}/')
        return f"{base_url}{url_pattern.format(slug=strain_slug)}"
    
    def _generate_contextual_actions(
        self,
        strains: List[Strain],
        language: str,
        session: ConversationSession
    ) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö quick actions"""
        
        actions = []
        
        if len(strains) > 1:
            # –î–µ–π—Å—Ç–≤–∏—è –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞
            if language == 'es':
                actions.append("Ver el m√°s potente")
                actions.append("Ver el m√°s suave") 
                actions.append("Comparar efectos")
            else:
                actions.append("Show strongest")
                actions.append("Show mildest")
                actions.append("Compare effects")
        
        # –î–æ–±–∞–≤–ª—è–µ–º –æ–ø—Ü–∏—é –ø–æ–∏—Å–∫–∞ –Ω–æ–≤—ã—Ö —Å–æ—Ä—Ç–æ–≤
        search_action = "Buscar m√°s opciones" if language == 'es' else "Find more options"
        actions.append(search_action)
        
        # –î–æ–±–∞–≤–ª—è–µ–º reset –µ—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ç–æ—Ä–∏—è
        if session.conversation_history:
            reset_action = "Empezar nueva b√∫squeda" if language == 'es' else "Start new search"
            actions.append(reset_action)
        
        return actions[:4]  # –ú–∞–∫—Å–∏–º—É–º 4 –¥–µ–π—Å—Ç–≤–∏—è
    
    def _get_new_search_suggestions(self, language: str) -> List[str]:
        """–ü–æ–ª—É—á–∏—Ç—å –ø—Ä–µ–¥–ª–æ–∂–µ–Ω–∏—è –¥–ª—è –Ω–æ–≤–æ–≥–æ –ø–æ–∏—Å–∫–∞"""
        
        if language == 'es':
            return ['Para dormir', 'Para energ√≠a', 'Para dolor', 'Para creatividad']
        else:
            return ['For sleep', 'For energy', 'For pain', 'For creativity']
    
    def _is_reset_command(self, query: str) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–æ–º–∞–Ω–¥—ã —Å–±—Ä–æ—Å–∞"""
        
        query_lower = query.lower()
        reset_indicators = [
            'empezar de nuevo', 'start over', 'nueva consulta', 'new search',
            'reset', 'reiniciar', 'comenzar otra vez'
        ]
        
        return any(indicator in query_lower for indicator in reset_indicators)
    
    def _detect_language(self, text: str) -> str:
        """–ü—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è —è–∑—ã–∫–∞"""
        
        spanish_indicators = ['para', 'necesito', 'quiero', 'cu√°l', 'qu√©', 'm√°s', 'mejor']
        text_lower = text.lower()
        
        spanish_count = sum(1 for word in spanish_indicators if word in text_lower)
        return 'es' if spanish_count > 0 else 'en'
    
    def _legacy_process_query(
        self,
        query: str,
        session: ConversationSession
    ) -> ChatResponse:
        """Fallback –∫ legacy –æ–±—Ä–∞–±–æ—Ç–∫–µ (–æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π RAG v2.0)"""
        
        logger.info("Using legacy processing mode")
        
        # –ò–º–ø–æ—Ä—Ç legacy —Å–µ—Ä–≤–∏—Å–∞
        from app.core.optimized_rag_service import OptimizedContextualRAGService
        
        # –°–æ–∑–¥–∞–Ω–∏–µ legacy —Å–µ—Ä–≤–∏—Å–∞ –∏ –æ–±—Ä–∞–±–æ—Ç–∫–∞
        legacy_service = OptimizedContextualRAGService(self.repository)
        return legacy_service.process_contextual_query(query, session.session_id)
    
    def get_service_info(self) -> Dict[str, Any]:
        """–ò–Ω—Ñ–æ—Ä–º–∞—Ü–∏—è –æ —Å–µ—Ä–≤–∏—Å–µ –¥–ª—è –º–æ–Ω–∏—Ç–æ—Ä–∏–Ω–≥–∞"""
        
        return {
            "service_name": "SmartRAGService",
            "version": "3.0",
            "smart_executor_enabled": self.use_smart_executor,
            "components": [
                "SmartQueryAnalyzer",
                "ContextProvider", 
                "ActionExecutor",
                "SessionManager"
            ],
            "fallback_available": True
        }