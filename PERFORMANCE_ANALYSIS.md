# ðŸ” Canagent Performance Analysis Report
**Date**: 2025-11-04
**Analysis**: Query Processing Performance Profiling

---

## ðŸ“Š Executive Summary

ÐÐ½Ð°Ð»Ð¸Ð· Ð¿Ð¾ÐºÐ°Ð·Ð°Ð», Ñ‡Ñ‚Ð¾ **Ð·Ð°Ð¿Ñ€Ð¾ÑÑ‹ Ð·Ð°Ð½Ð¸Ð¼Ð°ÑŽÑ‚ 40-42 ÑÐµÐºÑƒÐ½Ð´Ñ‹**, Ñ‡Ñ‚Ð¾ ÐÐ•ÐŸÐ Ð˜Ð•ÐœÐ›Ð•ÐœÐž Ð´Ð»Ñ production. Ð’Ñ‹ÑÐ²Ð»ÐµÐ½Ñ‹ **ÐšÐ Ð˜Ð¢Ð˜Ð§Ð•Ð¡ÐšÐ˜Ð• ÑƒÐ·ÐºÐ¸Ðµ Ð¼ÐµÑÑ‚Ð°**, Ñ‚Ñ€ÐµÐ±ÑƒÑŽÑ‰Ð¸Ðµ ÑÑ€Ð¾Ñ‡Ð½Ð¾Ð¹ Ð¾Ð¿Ñ‚Ð¸Ð¼Ð¸Ð·Ð°Ñ†Ð¸Ð¸.

| Metric | Value | Status |
|--------|-------|--------|
| Average Response Time | 40-42 sec | ðŸ”´ CRITICAL |
| Memory Usage Spike | +3.3 GB | ðŸ”´ CRITICAL |
| Database Query Time | 30.5 sec | ðŸ”´ CRITICAL (75% of total) |
| LLM Query Time | 8.8 sec | ðŸŸ¡ ACCEPTABLE |
| Vector Operations | 0.9 sec | ðŸŸ¢ OK |

---

## ðŸ”´ CRITICAL BOTTLENECK: Database Query (30.5 seconds)

### Problem
```
Database Query (get_strains): 30.522s [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 75.5%
```

**This single operation takes 75.5% of the entire request time!**

### Root Cause Analysis

The `get_strains_with_relations()` call is loading all 173 strains with ALL their relationships:
- âœ… Category
- âœ… Feelings/Effects
- âœ… Helps_with (Medical uses)
- âœ… Negatives (Side effects)
- âœ… Flavors/Terpenes
- âœ… Vector Embeddings (embedding_en, embedding_es)

**Problem**: Loading 173 strains Ã— 5-6 relationships each = potential N+1 query issue

### Code Location
`app/core/universal_action_executor.py:85` - `_execute_search_strains()`
```python
all_strains = self.repository.get_strains_with_relations(limit=200)
```

### Evidence from Logs
```
Loaded 173 strains from database
ðŸ”´ Database Query (get_strains)             |  30.522s | Mem:  +65.8MB | CPU:   0.0%
```

---

## ðŸŸ¡ SECONDARY ISSUE: LLM Analysis (8.8 seconds)

### Problem
```
Smart Query Analyzer (LLM):  8.836s [â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ] 21.9%
```

**OpenAI API call for query analysis takes 21.9% of total time.**

### Root Cause
- Single LLM call to analyze query and generate action plan
- Builds full context with session strains (even though there are 0 strains initially)
- Waits for OpenAI response

### Code Location
`app/core/smart_rag_service.py:114-125` - `process_contextual_query()`
```python
smart_analysis = self.smart_analyzer.analyze_query(
    query, session, session_strains, full_context, policy_hint
)
```

---

## ðŸŸ¢ THIRD ISSUE: Vector Operations (0.9 seconds)

### Current Status
- Query Embedding: **0.806s**
- Cosine Distance Calculation: **0.044s**
- Total: **0.871s** (2.2% of time)

**Status: âœ… ACCEPTABLE** - Vector operations are relatively fast

---

## ðŸ“ˆ Performance Breakdown (from actual test)

```
Query: "Find me hybrid strains with high THC and terpenes that help with anxiety"
Total Time: 40.406 seconds

Stage                          Time      % of Total
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
Database Query                30.522s   75.5% ðŸ”´ CRITICAL
Smart Query Analyzer (LLM)     8.836s   21.9% ðŸŸ¡ SECONDARY
Vector Embedding & Reranking   0.871s    2.2% ðŸŸ¢ OK
Query Embedding Generation     0.806s    2.0% ðŸŸ¢ OK
Cosine Distance Calculation    0.044s    0.1% ðŸŸ¢ OK
Other services                 0.056s    0.1% ðŸŸ¢ OK
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
TOTAL                         40.406s  100.0%
```

---

## ðŸ’¡ Recommended Solutions (Priority Order)

### PRIORITY 1: Fix Database Query (Could save 30 seconds)

#### Option A: Selective Relationship Loading (RECOMMENDED)
**Save: ~20-25 seconds**

Currently loading ALL relationships. Instead:
- Load full relationships only when needed
- For initial search: load minimal relationships (id, name, category, thc, cbd)
- For final results: load full details

```python
# Before: Loads everything
all_strains = self.repository.get_strains_with_relations(limit=200)

# After: Load minimal data for filtering
all_strains = self.repository.get_strains_minimal(limit=200)
# Then load full details only for top 5 results
detailed_strains = self.repository.get_strains_with_relations(ids=[1,2,3,4,5])
```

**Implementation**:
- Create new repository method: `get_strains_minimal()`
- Load only: id, name, category, thc, cbd, cbg
- Skip: feelings, helps_with, negatives, flavors, terpenes, embeddings (for initial filtering)

#### Option B: Database Connection Pooling
**Save: ~2-5 seconds**

The +65.8MB memory spike suggests inefficient connection/query handling
- SQLAlchemy session pooling
- Connection reuse
- Query result caching

#### Option C: Caching Strain Data
**Save: ~15-25 seconds on repeated queries**

Cache all strains in Redis with 1-hour TTL:
```python
# Check cache first
cached_strains = cache.get("all_strains:173")
if not cached_strains:
    # Load from DB and cache
    all_strains = self.repository.get_strains_with_relations(limit=200)
    cache.set("all_strains:173", all_strains, ttl=3600)
```

---

### PRIORITY 2: Optimize LLM Analysis (Could save 5-8 seconds)

#### Option A: Parallel API Calls
**Save: ~0-2 seconds**

If LLM is being called multiple times, parallelize with asyncio

#### Option B: Caching LLM Analysis
**Save: ~5-8 seconds on similar queries**

Cache analysis results for similar queries:
```python
# Hash the query and check cache
query_hash = md5(query).hexdigest()
cached_analysis = cache.get(f"llm_analysis:{query_hash}")
if cached_analysis:
    return cached_analysis
```

#### Option C: Use Faster LLM Model
**Save: ~2-4 seconds**

Current: `gpt-3.5-turbo` (reasonable)
- Could use `gpt-3.5-turbo-instruct` for faster inference
- Or batch multiple queries together

---

### PRIORITY 3: Optimize Vector Operations (Already OK)

Vector operations are only 2.2% of time. **No urgent action needed**, but:
- Consider caching embeddings if regenerated frequently
- Cosine distance calculation is efficient via pgvector

---

## ðŸš€ Quick Wins (Easy to Implement)

| Fix | Estimated Save | Effort | Impact |
|-----|-----------------|--------|--------|
| Minimal relationship loading | 20-25s | Medium | CRITICAL |
| Strain caching (Redis) | 15-25s | Low | HIGH |
| LLM analysis caching | 5-8s | Low | HIGH |
| Connection pooling | 2-5s | Medium | MEDIUM |
| Async/parallel calls | 0-2s | Medium | LOW |

---

## ðŸ“Š Expected Results After Optimization

### Scenario 1: Implement Minimal Loading + Caching
- **Before**: 40-42 seconds
- **After**: 5-8 seconds
- **Improvement**: 80-85% faster âœ…

### Scenario 2: Implement All Recommendations
- **Before**: 40-42 seconds
- **After**: 2-3 seconds
- **Improvement**: 93-95% faster âœ…âœ…

---

## ðŸ”§ Implementation Steps

### Step 1: Create Minimal Repository Method
**File**: `app/db/repository.py`

```python
def get_strains_minimal(self, limit: int = 200) -> List[Strain]:
    """
    Load strains with minimal relationships for fast filtering.
    Only includes: id, name, category, thc, cbd, cbg
    """
    return self.db.query(Strain)\
        .options(
            # Load only what's needed for filtering
            joinedload(Strain.category)  # for category filtering
        )\
        .limit(limit)\
        .all()

def get_strains_full(self, strain_ids: List[int]) -> List[Strain]:
    """
    Load specific strains with ALL relationships.
    Called only for final results.
    """
    return self.db.query(Strain)\
        .options(
            joinedload(Strain.feelings),
            joinedload(Strain.helps_with),
            joinedload(Strain.negatives),
            joinedload(Strain.flavors),
            joinedload(Strain.terpenes)
        )\
        .filter(Strain.id.in_(strain_ids))\
        .all()
```

### Step 2: Update Action Executor

**File**: `app/core/universal_action_executor.py:66-91`

```python
# Before: Load all with all relationships (30s)
all_strains = self.repository.get_strains_with_relations(limit=200)

# After: Load minimal for filtering
all_strains = self.repository.get_strains_minimal(limit=200)
# ... filtering and scoring ...
# Load full details only for final results
top_ids = [s.id for s in result_strains]
result_strains = self.repository.get_strains_full(top_ids)
```

### Step 3: Add Redis Caching

**File**: `app/core/universal_action_executor.py:66-91`

```python
from app.core.cache import cache_service

# Try cache first
cached_strains = cache_service.get("strains:minimal:all")
if cached_strains:
    all_strains = cached_strains
else:
    # Load and cache for 1 hour
    all_strains = self.repository.get_strains_minimal(limit=200)
    cache_service.set("strains:minimal:all", all_strains, ttl=3600)
```

---

## ðŸ“‰ Memory Analysis

### Current Memory Usage
- **Start**: 95.3 MB
- **After DB Query**: 161.1 MB (+65.8 MB)
- **Final**: 340+ MB (+245 MB total)

### Problem
Loading 173 strains with all relationships in memory = huge data structures

### Solution
Lazy-load relationships only when needed reduces memory by ~70%

---

## ðŸŽ¯ Monitoring Recommendations

After implementing fixes, monitor these metrics:

```python
# Add to logs
logger.info(f"DB query time: {db_time:.3f}s")
logger.info(f"Memory delta: {memory_delta:+.1f}MB")
logger.info(f"Strains loaded: {len(strains)}")
logger.info(f"Cache hit: {cache_hit}")
logger.info(f"Total response time: {total_time:.3f}s")
```

---

## ðŸš¨ Critical Action Items

- [ ] **IMMEDIATE**: Implement minimal relationship loading (saves 20-25s)
- [ ] **URGENT**: Add Redis caching for strain data (saves 15-25s)
- [ ] **TODAY**: Add query result caching for LLM analysis (saves 5-8s)
- [ ] **THIS WEEK**: Set up performance monitoring dashboard
- [ ] **THIS WEEK**: Create performance regression tests

---

## ðŸ“ž Support

For detailed implementation:
1. Check `PERFORMANCE_OPTIMIZATION_GUIDE.md` (to be created)
2. Review existing repository methods in `app/db/repository.py`
3. Look at cache usage in `app/core/cache.py`

---

**Generated**: 2025-11-04
**Confidence**: HIGH (based on detailed profiling)
**Next Steps**: Implement Priority 1 fixes for 80%+ improvement
