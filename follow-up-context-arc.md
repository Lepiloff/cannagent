# –ê—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–∞ Context-Aware AI Budtender v2.0 (Optimized)

## –û–±–∑–æ—Ä –ø—Ä–æ–±–ª–µ–º—ã

**–¢–µ–∫—É—â–∞—è –ø—Ä–æ–±–ª–µ–º–∞:** AI –∞–≥–µ–Ω—Ç –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ –æ—Ç–≤–µ—á–∞–µ—Ç –Ω–∞ –∑–∞–ø—Ä–æ—Å—ã –ø–æ–¥–±–æ—Ä–∞ —Å–æ—Ä—Ç–æ–≤, –Ω–æ —Ç–µ—Ä—è–µ—Ç –∫–æ–Ω—Ç–µ–∫—Å—Ç –æ–±—Å—É–∂–¥–µ–Ω–∏—è. –ü—Ä–∏ follow-up –∑–∞–ø—Ä–æ—Å–∞—Ö —Å–∏—Å—Ç–µ–º–∞ –≤—ã–ø–æ–ª–Ω—è–µ—Ç –Ω–æ–≤—ã–π –ø–æ–∏—Å–∫ –≤–º–µ—Å—Ç–æ —Ä–∞–±–æ—Ç—ã —Å —É–∂–µ —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã–º–∏ —Å–æ—Ä—Ç–∞–º–∏.

**–¶–µ–ª—å:** –†–µ–∞–ª–∏–∑–æ–≤–∞—Ç—å –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—É—é —Å–∏—Å—Ç–µ–º—É —É–ø—Ä–∞–≤–ª–µ–Ω–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º —Å –º–∏–Ω–∏–º–∞–ª—å–Ω—ã–º–∏ –≤—ã–∑–æ–≤–∞–º–∏ LLM –∏ robust fallback –º–µ—Ö–∞–Ω–∏–∑–º–∞–º–∏.

---

## üîµ BACKEND (Canagent API) - –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è –≤–µ—Ä—Å–∏—è

### 1. Unified LLM Processor (–ö–õ–Æ–ß–ï–í–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï)

#### 1.1 –ï–¥–∏–Ω—ã–π –ø—Ä–æ—Ü–µ—Å—Å–æ—Ä –¥–ª—è –≤—Å–µ—Ö –æ–ø–µ—Ä–∞—Ü–∏–π
```python
# app/core/unified_processor.py

class UnifiedLLMProcessor:
    """–û–±—ä–µ–¥–∏–Ω—è–µ—Ç –≤—Å–µ LLM –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ –æ–¥–∏–Ω –≤—ã–∑–æ–≤ –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    
    def analyze_complete(
        self, 
        query: str, 
        session: ConversationSession
    ) -> UnifiedAnalysis:
        """–û–î–ò–ù –≤—ã–∑–æ–≤ LLM –≤–º–µ—Å—Ç–æ 4-5"""
        
        prompt = """
        Analyze this cannabis consultation query and return complete analysis in JSON.
        
        Query: {query}
        Language hint: {last_language}
        Has previous recommendations: {has_strains}
        Last strains: {last_strains}
        Previous topic: {previous_topic}
        User preferences accumulated: {preferences}
        
        Return JSON with ALL of the following:
        {{
            "detected_language": "es|en",
            "query_type": "new_search|follow_up|comparison|detail_request|reset|clarification",
            "confidence": 0.0-1.0,
            "topic_changed": true|false,
            "criteria": {{
                "potency": {{"thc": "higher|lower|specific", "value": null}},
                "effects": {{"desired": [], "avoid": [], "priority": ""}},
                "medical_conditions": [],
                "flavors": {{"preferred": [], "avoid": []}},
                "strain_reference": {{"type": "index|name|all", "value": ""}},
                "custom_criteria": "",
                "conflicts_detected": []
            }},
            "action_needed": "filter|sort|compare|select|explain|clarify",
            "suggested_quick_actions": ["dynamic suggestions based on context"],
            "response_text": "Generated natural response in detected language"
        }}
        
        Critical instructions:
        - Detect if this is about previously mentioned strains (follow_up)
        - Check for conflicting criteria (e.g., "sleepy but energetic")
        - Generate response text in the detected language
        - Suggest relevant quick actions based on the context
        """
        
        context_summary = self._build_context_summary(session)
        
        try:
            result = self.llm.extract_json(
                prompt.format(
                    query=query,
                    last_language=session.detected_language or 'es',
                    has_strains=bool(session.recommended_strains_history),
                    last_strains=self._format_last_strains(session),
                    previous_topic=session.current_topic,
                    preferences=session.user_preferences
                )
            )
            
            return UnifiedAnalysis(**result)
            
        except Exception as e:
            # Fallback –Ω–∞ –ø—Ä–∞–≤–∏–ª–∞ –µ—Å–ª–∏ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω
            return self.fallback_analyzer.analyze(query, session)
```

#### 1.2 Fallback –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –Ω–∞ –ø—Ä–∞–≤–∏–ª–∞—Ö
```python
# app/core/fallback_analyzer.py

class RuleBasedFallbackAnalyzer:
    """–†–µ–∑–µ—Ä–≤–Ω—ã–π –∞–Ω–∞–ª–∏–∑–∞—Ç–æ—Ä –∫–æ–≥–¥–∞ LLM –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω"""
    
    def analyze(self, query: str, session: ConversationSession) -> UnifiedAnalysis:
        """–ü—Ä–æ—Å—Ç–æ–π rule-based –∞–Ω–∞–ª–∏–∑ –±–µ–∑ LLM"""
        
        query_lower = query.lower()
        
        # –î–µ—Ç–µ–∫—Ü–∏—è —è–∑—ã–∫–∞ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        language = 'es' if any(word in query_lower for word in 
                               ['necesito', 'quiero', 'cu√°l', 'para']) else 'en'
        
        # –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Ç–∏–ø–∞ –∑–∞–ø—Ä–æ—Å–∞
        query_type = self._detect_query_type_by_rules(query_lower, session)
        
        # –ë–∞–∑–æ–≤—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –ø–æ –∫–ª—é—á–µ–≤—ã–º —Å–ª–æ–≤–∞–º
        criteria = self._extract_basic_criteria(query_lower)
        
        # –ü—Ä–æ—Å—Ç–æ–π –æ—Ç–≤–µ—Ç
        response = self._generate_simple_response(query_type, language)
        
        return UnifiedAnalysis(
            detected_language=language,
            query_type=query_type,
            confidence=0.5,  # –ù–∏–∑–∫–∞—è —É–≤–µ—Ä–µ–Ω–Ω–æ—Å—Ç—å –¥–ª—è fallback
            criteria=criteria,
            response_text=response,
            is_fallback=True
        )
    
    def _detect_query_type_by_rules(self, query: str, session: ConversationSession):
        """–ü—Ä–æ—Å—Ç—ã–µ –ø—Ä–∞–≤–∏–ª–∞ –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —Ç–∏–ø–∞"""
        
        # Reset patterns
        if any(p in query for p in ['empezar de nuevo', 'start over', 'nueva consulta']):
            return 'reset'
        
        # Follow-up indicators
        if session.recommended_strains_history:
            follow_up_words = ['cu√°l', 'which', 'mejor', 'better', 'primero', 
                              'first', '√∫ltimo', 'last', 'estos', 'these']
            if any(word in query for word in follow_up_words):
                return 'follow_up'
        
        return 'new_search'
```

### 2. Enhanced Session Management

#### 2.1 Session Model —Å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º
```python
# app/models/session.py

class ConversationSession:
    session_id: str
    created_at: datetime
    last_activity: datetime
    detected_language: str
    is_restored: bool = False  # –§–ª–∞–≥ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–Ω–æ–π —Å–µ—Å—Å–∏–∏
    
    # –ò—Å—Ç–æ—Ä–∏—è —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º
    recommended_strains_history: List[List[int]]  # –ú–∞–∫—Å 20
    current_topic: Optional[IntentType]
    previous_topics: List[IntentType]
    
    # –ù–∞–∫–æ–ø–ª–µ–Ω–Ω—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
    user_preferences: Dict[str, Set[str]]
    
    # –î–µ—Ç–∞–ª—å–Ω–∞—è –∏—Å—Ç–æ—Ä–∏—è
    conversation_history: List[Dict]
    
    def has_strains(self) -> bool:
        """–ü—Ä–æ–≤–µ—Ä–∫–∞ –Ω–∞–ª–∏—á–∏—è —Ä–µ–∫–æ–º–µ–Ω–¥–æ–≤–∞–Ω–Ω—ã—Ö —Å–æ—Ä—Ç–æ–≤"""
        return bool(self.recommended_strains_history)
    
    def get_last_strains(self) -> List[int]:
        """–ë–µ–∑–æ–ø–∞—Å–Ω–æ–µ –ø–æ–ª—É—á–µ–Ω–∏–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö —Å–æ—Ä—Ç–æ–≤"""
        if self.recommended_strains_history:
            return self.recommended_strains_history[-1]
        return []
```

#### 2.2 –£–ª—É—á—à–µ–Ω–Ω—ã–π Session Manager
```python
# app/core/session_manager.py

class ImprovedSessionManager:
    """–ú–µ–Ω–µ–¥–∂–µ—Ä —Å–µ—Å—Å–∏–π —Å graceful –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º"""
    
    def __init__(self, redis_client, repository):
        self.redis = redis_client
        self.repository = repository
        self.session_ttl = 3600 * 4
        
    def get_or_restore_session(self, session_id: Optional[str]) -> ConversationSession:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ –∏–ª–∏ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏"""
        
        if not session_id:
            return self.create_new_session()
        
        # –ü–æ–ø—ã—Ç–∫–∞ –ø–æ–ª—É—á–∏—Ç—å –∞–∫—Ç–∏–≤–Ω—É—é —Å–µ—Å—Å–∏—é
        session = self.get_active_session(session_id)
        
        if not session:
            # –ü–æ–ø—ã—Ç–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è –±–∞–∑–æ–≤–æ–≥–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            session = self.restore_expired_session(session_id)
            
        return session
    
    def restore_expired_session(self, session_id: str) -> ConversationSession:
        """–í–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –∏—Å—Ç–µ–∫—à–µ–π —Å–µ—Å—Å–∏–∏ —Å –±–∞–∑–æ–≤—ã–º –∫–æ–Ω—Ç–µ–∫—Å—Ç–æ–º"""
        
        session = ConversationSession(
            session_id=session_id,
            created_at=datetime.now(),
            is_restored=True
        )
        
        # –ü–æ–ø—ã—Ç–∫–∞ –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –ø–æ—Å–ª–µ–¥–Ω–∏–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è –∏–∑ backup
        backup_key = f"backup:{session_id}"
        if self.redis.exists(backup_key):
            preferences = self.redis.get(backup_key)
            session.user_preferences = preferences
        
        return session
    
    def save_session_with_backup(self, session: ConversationSession):
        """–°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å backup –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è"""
        
        # –û—Å–Ω–æ–≤–Ω–æ–µ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ
        self.redis.setex(
            f"session:{session.session_id}",
            self.session_ttl,
            session.to_json()
        )
        
        # Backup –∫–ª—é—á–µ–≤—ã—Ö –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π (–Ω–∞ 7 –¥–Ω–µ–π)
        self.redis.setex(
            f"backup:{session.session_id}",
            86400 * 7,
            json.dumps(session.user_preferences)
        )
```

### 3. Embedding Cache System

```python
# app/core/embedding_cache.py

class EmbeddingCache:
    """–ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ embeddings –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏"""
    
    def __init__(self, redis_client, llm_interface):
        self.redis = redis_client
        self.llm = llm_interface
        self.cache_ttl = 86400  # 24 —á–∞—Å–∞
    
    def get_strain_embedding(self, strain_id: int, strain_text: str) -> List[float]:
        """–ü–æ–ª—É—á–µ–Ω–∏–µ embedding —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
        
        cache_key = f"embedding:strain:{strain_id}"
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –∫–µ—à–∞
        cached = self.redis.get(cache_key)
        if cached:
            return json.loads(cached)
        
        # –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –µ—Å–ª–∏ –Ω–µ—Ç –≤ –∫–µ—à–µ
        embedding = self.llm.generate_embedding(strain_text)
        
        # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –≤ –∫–µ—à
        self.redis.setex(
            cache_key,
            self.cache_ttl,
            json.dumps(embedding)
        )
        
        return embedding
    
    def get_query_embedding(self, query: str) -> List[float]:
        """–ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ embeddings –∑–∞–ø—Ä–æ—Å–æ–≤"""
        
        # –•–µ—à–∏—Ä—É–µ–º –∑–∞–ø—Ä–æ—Å –¥–ª—è –∫–ª—é—á–∞
        query_hash = hashlib.md5(query.encode()).hexdigest()
        cache_key = f"embedding:query:{query_hash}"
        
        cached = self.redis.get(cache_key)
        if cached:
            return json.loads(cached)
        
        embedding = self.llm.generate_embedding(query)
        
        # –ö–æ—Ä–æ—Ç–∫–∏–π TTL –¥–ª—è –∑–∞–ø—Ä–æ—Å–æ–≤ (1 —á–∞—Å)
        self.redis.setex(cache_key, 3600, json.dumps(embedding))
        
        return embedding
```

### 4. Criteria Conflict Resolver

```python
# app/core/conflict_resolver.py

class CriteriaConflictResolver:
    """–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –≤ –∫—Ä–∏—Ç–µ—Ä–∏—è—Ö"""
    
    CONFLICTING_EFFECTS = [
        ({'Sleepy', 'Relaxed'}, {'Energetic', 'Uplifted'}),
        ({'Focused'}, {'Giggly', 'Tingly'}),
        ({'Hungry'}, {'Appetite Loss'}),
    ]
    
    def resolve_conflicts(
        self,
        criteria: Dict,
        context: str
    ) -> Tuple[Dict, List[str]]:
        """–†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ —Å –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è–º–∏"""
        
        conflicts = []
        resolved_criteria = criteria.copy()
        
        if 'effects' in criteria:
            desired = set(criteria['effects'].get('desired', []))
            avoid = set(criteria['effects'].get('avoid', []))
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä—è–º—ã—Ö –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
            direct_conflicts = desired & avoid
            if direct_conflicts:
                conflicts.append(f"Conflicting: want and avoid {direct_conflicts}")
                # –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç –Ω–∞ desired
                resolved_criteria['effects']['avoid'] = list(avoid - direct_conflicts)
            
            # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤
            for group1, group2 in self.CONFLICTING_EFFECTS:
                if desired & group1 and desired & group2:
                    conflicts.append(f"Conflicting effects: {group1} vs {group2}")
                    # –û—Å—Ç–∞–≤–ª—è–µ–º –ø–µ—Ä–≤—ã–π —É–ø–æ–º—è–Ω—É—Ç—ã–π
                    resolved_criteria['effects']['priority'] = self._determine_priority(
                        context, group1, group2
                    )
        
        return resolved_criteria, conflicts
    
    def _determine_priority(self, context: str, group1: set, group2: set) -> str:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞ –Ω–∞ –æ—Å–Ω–æ–≤–µ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        # –ê–Ω–∞–ª–∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞ –¥–ª—è –≤—ã–±–æ—Ä–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–∞
        context_lower = context.lower()
        
        if any(word in context_lower for word in ['dormir', 'sleep', 'insomnia']):
            return list(group1)[0] if 'Sleepy' in group1 else list(group2)[0]
        elif any(word in context_lower for word in ['trabajar', 'work', 'focus']):
            return list(group1)[0] if 'Focused' in group1 else list(group2)[0]
        
        return list(group1)[0]  # –ü–æ —É–º–æ–ª—á–∞–Ω–∏—é –ø–µ—Ä–≤—ã–π
```

### 5. Optimized Contextual RAG Service

```python
# app/core/optimized_rag_service.py

class OptimizedContextualRAGService:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π RAG —Å –µ–¥–∏–Ω—ã–º LLM –≤—ã–∑–æ–≤–æ–º"""
    
    def __init__(self, repository, session_manager):
        self.repository = repository
        self.session_manager = session_manager
        self.unified_processor = UnifiedLLMProcessor()
        self.fallback_analyzer = RuleBasedFallbackAnalyzer()
        self.embedding_cache = EmbeddingCache()
        self.conflict_resolver = CriteriaConflictResolver()
        self.dynamic_filter = DynamicStrainFilter()
    
    def process_contextual_query(
        self,
        query: str,
        session_id: Optional[str],
        history: Optional[List[str]]
    ) -> ChatResponse:
        """–ì–ª–∞–≤–Ω—ã–π –º–µ—Ç–æ–¥ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π –∏ fallbacks"""
        
        # 1. –£–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–µ–π —Å –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ–º
        session = self.session_manager.get_or_restore_session(session_id)
        
        # 2. –ï–î–ò–ù–´–ô –∞–Ω–∞–ª–∏–∑ —á–µ—Ä–µ–∑ LLM –∏–ª–∏ fallback
        try:
            analysis = self.unified_processor.analyze_complete(query, session)
        except Exception as e:
            logger.warning(f"LLM failed, using fallback: {e}")
            analysis = self.fallback_analyzer.analyze(query, session)
        
        # 3. –û–±—Ä–∞–±–æ—Ç–∫–∞ –∫–æ–º–∞–Ω–¥—ã —Å–±—Ä–æ—Å–∞
        if analysis.query_type == 'reset':
            return self._handle_reset(session)
        
        # 4. –û–±—Ä–∞–±–æ—Ç–∫–∞ edge cases
        if analysis.query_type == 'follow_up' and not session.has_strains():
            return self._handle_no_context(analysis.detected_language)
        
        # 5. –†–∞–∑—Ä–µ—à–µ–Ω–∏–µ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–æ–≤ –≤ –∫—Ä–∏—Ç–µ—Ä–∏—è—Ö
        if analysis.criteria:
            resolved_criteria, conflicts = self.conflict_resolver.resolve_conflicts(
                analysis.criteria, query
            )
            analysis.criteria = resolved_criteria
            if conflicts:
                analysis.warnings = conflicts
        
        # 6. –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ —Ç–∏–ø—É –∑–∞–ø—Ä–æ—Å–∞
        strains = self._process_by_type(analysis, session)
        
        # 7. –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–∏
        self._update_session(session, query, analysis, strains)
        
        # 8. –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ —Å backup
        self.session_manager.save_session_with_backup(session)
        
        # 9. –ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞
        return self._build_optimized_response(analysis, strains, session)
    
    def _handle_no_context(self, language: str) -> ChatResponse:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ follow-up –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        
        responses = {
            'es': "No tengo variedades anteriores para comparar. ¬øQu√© efectos buscas?",
            'en': "I don't have previous strains to compare. What effects are you looking for?"
        }
        
        return ChatResponse(
            response=responses.get(language, responses['es']),
            recommended_strains=[],
            detected_intent='no_context',
            filters_applied={},
            session_id=session.session_id,
            query_type='clarification',
            language=language,
            confidence=1.0,
            quick_actions=self._get_new_search_suggestions(language)
        )
    
    def _handle_reset(self, session: ConversationSession) -> ChatResponse:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ —Å–±—Ä–æ—Å–∞ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞"""
        
        # –°–æ—Ö—Ä–∞–Ω—è–µ–º —Ç–æ–ª—å–∫–æ –±–∞–∑–æ–≤—ã–µ –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏—è
        preserved_preferences = session.user_preferences.copy()
        
        # –û—á–∏—â–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é
        session.recommended_strains_history = []
        session.conversation_history = []
        session.current_topic = None
        
        responses = {
            'es': "Perfecto, empecemos de nuevo. ¬øQu√© tipo de efectos buscas?",
            'en': "Perfect, let's start fresh. What kind of effects are you looking for?"
        }
        
        return ChatResponse(
            response=responses.get(session.detected_language, responses['es']),
            recommended_strains=[],
            detected_intent='reset',
            filters_applied={},
            session_id=session.session_id,
            query_type='reset',
            language=session.detected_language,
            confidence=1.0
        )
    
    def _process_by_type(
        self,
        analysis: UnifiedAnalysis,
        session: ConversationSession
    ) -> List[Strain]:
        """–û–±—Ä–∞–±–æ—Ç–∫–∞ –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ç–∏–ø–∞ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
        
        if analysis.query_type == 'follow_up':
            # –†–∞–±–æ—Ç–∞–µ–º —Å —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–º–∏ —Å–æ—Ä—Ç–∞–º–∏
            strain_ids = session.get_last_strains()
            strains = [self.repository.get_strain_with_relations(id) for id in strain_ids]
            
            # –ü—Ä–∏–º–µ–Ω—è–µ–º —Ñ–∏–ª—å—Ç—Ä—ã –µ—Å–ª–∏ –µ—Å—Ç—å
            if analysis.criteria:
                strains = self.dynamic_filter.apply_criteria(strains, analysis.criteria)
            
            return strains
        
        elif analysis.query_type == 'new_search':
            # –ù–æ–≤—ã–π –ø–æ–∏—Å–∫ —Å —É—á–µ—Ç–æ–º –ø—Ä–µ–¥–ø–æ—á—Ç–µ–Ω–∏–π
            return self._optimized_search(analysis, session)
        
        elif analysis.query_type == 'comparison':
            # –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –∏–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
            return self._handle_comparison(analysis, session)
        
        else:
            # Default - –ø–æ–∫–∞–∑—ã–≤–∞–µ–º –ø–æ—Å–ª–µ–¥–Ω–∏–µ –µ—Å–ª–∏ –µ—Å—Ç—å
            if session.has_strains():
                strain_ids = session.get_last_strains()
                return [self.repository.get_strain_with_relations(id) for id in strain_ids][:3]
            return []
    
    def _optimized_search(
        self,
        analysis: UnifiedAnalysis,
        session: ConversationSession
    ) -> List[Strain]:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –ø–æ–∏—Å–∫ —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–º–∏ embeddings"""
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ embedding –∑–∞–ø—Ä–æ—Å–∞
        query_embedding = self.embedding_cache.get_query_embedding(
            analysis.original_query
        )
        
        # –ü–æ–∏—Å–∫ —Å —Ñ–∏–ª—å—Ç—Ä–∞–º–∏
        strains = self.repository.search_strains_with_filters(
            embedding=query_embedding,
            filters=self._merge_filters(analysis.criteria, session.user_preferences),
            limit=5
        )
        
        return strains
    
    def _build_optimized_response(
        self,
        analysis: UnifiedAnalysis,
        strains: List[Strain],
        session: ConversationSession
    ) -> ChatResponse:
        """–ü–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ –æ—Ç–≤–µ—Ç–∞ —Å –¥–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–º–∏ quick actions"""
        
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º —É–∂–µ —Å–≥–µ–Ω–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç –∏–∑ unified analysis
        response_text = analysis.response_text
        
        # –î–æ–±–∞–≤–ª—è–µ–º –ø—Ä–µ–¥—É–ø—Ä–µ–∂–¥–µ–Ω–∏—è –æ –∫–æ–Ω—Ñ–ª–∏–∫—Ç–∞—Ö
        if hasattr(analysis, 'warnings') and analysis.warnings:
            warning_text = f"\n‚ö†Ô∏è {', '.join(analysis.warnings)}"
            response_text += warning_text
        
        # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ quick actions
        quick_actions = self._generate_dynamic_quick_actions(
            strains, 
            analysis,
            session
        )
        
        # –ö–æ–º–ø–∞–∫—Ç–Ω—ã–µ —Å–æ—Ä—Ç–∞ –¥–ª—è UI
        compact_strains = self._build_compact_strains(strains)
        
        return ChatResponse(
            response=response_text,
            recommended_strains=compact_strains,
            detected_intent=analysis.query_type,
            filters_applied=analysis.criteria or {},
            session_id=session.session_id,
            query_type=analysis.query_type,
            language=analysis.detected_language,
            confidence=analysis.confidence,
            quick_actions=quick_actions or analysis.suggested_quick_actions,
            is_restored=session.is_restored,
            is_fallback=getattr(analysis, 'is_fallback', False)
        )
    
    def _generate_dynamic_quick_actions(
        self,
        strains: List[Strain],
        analysis: UnifiedAnalysis,
        session: ConversationSession
    ) -> List[str]:
        """–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–Ω—ã—Ö quick actions"""
        
        actions = []
        lang = analysis.detected_language
        
        if len(strains) > 1:
            # –î–µ–π—Å—Ç–≤–∏—è –¥–ª—è –º–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –≤—ã–±–æ—Ä–∞
            if lang == 'es':
                actions.append(f"Comparar {strains[0].name} y {strains[1].name}")
                actions.append("Ver el m√°s potente")
                actions.append("Ver el m√°s suave")
            else:
                actions.append(f"Compare {strains[0].name} and {strains[1].name}")
                actions.append("Show strongest")
                actions.append("Show mildest")
        
        if strains and any(s.thc and float(s.thc) > 20 for s in strains):
            # –ï—Å–ª–∏ –µ—Å—Ç—å —Å–∏–ª—å–Ω—ã–µ —Å–æ—Ä—Ç–∞
            action = "Ver opciones m√°s suaves" if lang == 'es' else "Show milder options"
            actions.append(action)
        
        # –î–æ–±–∞–≤–ª—è–µ–º reset –æ–ø—Ü–∏—é –µ—Å–ª–∏ –µ—Å—Ç—å –∏—Å—Ç–æ—Ä–∏—è
        if session.conversation_history:
            reset = "Empezar nueva b√∫squeda" if lang == 'es' else "Start new search"
            actions.append(reset)
        
        return actions[:4]  # –ú–∞–∫—Å–∏–º—É–º 4 –¥–µ–π—Å—Ç–≤–∏—è
```

### 6. Dynamic Filter —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π

```python
# app/core/dynamic_filter_optimized.py

class OptimizedDynamicFilter:
    """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã —Å –∫–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ–º"""
    
    def __init__(self, embedding_cache):
        self.embedding_cache = embedding_cache
    
    def apply_criteria(
        self,
        strains: List[Strain],
        criteria: Dict
    ) -> List[Strain]:
        """–ü—Ä–∏–º–µ–Ω–µ–Ω–∏–µ –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤ —Å –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–µ–π"""
        
        if not criteria or not strains:
            return strains
        
        result = strains.copy()
        
        # –ë—ã—Å—Ç—Ä—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã (–±–µ–∑ embeddings)
        if 'potency' in criteria:
            result = self._filter_by_potency(result, criteria['potency'])
        
        if 'effects' in criteria:
            result = self._filter_by_effects(result, criteria['effects'])
        
        # –ú–µ–¥–ª–µ–Ω–Ω—ã–µ —Ñ–∏–ª—å—Ç—Ä—ã (—Å embeddings) —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        if 'custom_criteria' in criteria and criteria['custom_criteria']:
            result = self._apply_semantic_filter_optimized(
                result, 
                criteria['custom_criteria']
            )
        
        return result
    
    def _apply_semantic_filter_optimized(
        self,
        strains: List[Strain],
        criteria_text: str
    ) -> List[Strain]:
        """–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω—ã–π semantic filter —Å –∫–µ—à–µ–º"""
        
        # –ö–µ—à–∏—Ä–æ–≤–∞–Ω–Ω–æ–µ embedding –¥–ª—è –∫—Ä–∏—Ç–µ—Ä–∏—è
        criteria_embedding = self.embedding_cache.get_query_embedding(criteria_text)
        
        scored_strains = []
        for strain in strains:
            # –ò—Å–ø–æ–ª—å–∑—É–µ–º –∫–µ—à–∏—Ä–æ–≤–∞–Ω–Ω—ã–µ embeddings —Å–æ—Ä—Ç–æ–≤
            strain_embedding = self.embedding_cache.get_strain_embedding(
                strain.id,
                self._build_strain_text(strain)
            )
            
            similarity = cosine_similarity(criteria_embedding, strain_embedding)
            scored_strains.append((strain, similarity))
        
        # –í–æ–∑–≤—Ä–∞—â–∞–µ–º —Ç–æ–ª—å–∫–æ —Ä–µ–ª–µ–≤–∞–Ω—Ç–Ω—ã–µ
        threshold = 0.7
        filtered = [s for s in scored_strains if s[1] >= threshold]
        return [s[0] for s in sorted(filtered, key=lambda x: x[1], reverse=True)]
```

### 7. Topic Change Detector

```python
# app/core/topic_detector.py

class TopicChangeDetector:
    """–î–µ—Ç–µ–∫—Ü–∏—è —Å–º–µ–Ω—ã —Ç–µ–º—ã —Ä–∞–∑–≥–æ–≤–æ—Ä–∞"""
    
    OPPOSITE_INTENTS = [
        (IntentType.SLEEP, IntentType.ENERGY),
        (IntentType.RELAXATION, IntentType.FOCUS),
        (IntentType.PAIN_RELIEF, IntentType.RECREATION)
    ]
    
    def detect_topic_change(
        self,
        new_intent: IntentType,
        current_topic: Optional[IntentType],
        query: str
    ) -> bool:
        """–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–º–µ–Ω—ã —Ç–µ–º—ã"""
        
        if not current_topic:
            return False
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –ø—Ä–æ—Ç–∏–≤–æ–ø–æ–ª–æ–∂–Ω—ã—Ö –Ω–∞–º–µ—Ä–µ–Ω–∏–π
        for intent1, intent2 in self.OPPOSITE_INTENTS:
            if (current_topic == intent1 and new_intent == intent2) or \
               (current_topic == intent2 and new_intent == intent1):
                return True
        
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ —è–≤–Ω—ã—Ö –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å–º–µ–Ω—ã
        change_indicators = [
            'ahora necesito', 'now i need',
            'cambiando de tema', 'changing topic',
            'otra cosa', 'something else'
        ]
        
        query_lower = query.lower()
        return any(indicator in query_lower for indicator in change_indicators)
```

---

## üü¢ FRONTEND (Chat Client)

### 1. Enhanced Session Management

```javascript
// app.js - –£–ª—É—á—à–µ–Ω–Ω–æ–µ —É–ø—Ä–∞–≤–ª–µ–Ω–∏–µ —Å–µ—Å—Å–∏–µ–π

class EnhancedSessionManager {
    constructor() {
        this.sessionId = this.getOrCreateSessionId();
        this.isRestored = false;
        this.language = null;
        this.lastActivity = Date.now();
    }
    
    getOrCreateSessionId() {
        let sessionId = sessionStorage.getItem('canagent_session_id');
        const lastActivity = sessionStorage.getItem('canagent_last_activity');
        
        // –ü—Ä–æ–≤–µ—Ä–∫–∞ –∏—Å—Ç–µ—á–µ–Ω–∏—è (4 —á–∞—Å–∞)
        if (sessionId && lastActivity) {
            const elapsed = Date.now() - parseInt(lastActivity);
            if (elapsed > 4 * 60 * 60 * 1000) {
                // –°–µ—Å—Å–∏—è –∏—Å—Ç–µ–∫–ª–∞, –Ω–æ —Å–æ—Ö—Ä–∞–Ω—è–µ–º ID –¥–ª—è –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏—è
                this.isRestored = true;
            }
        }
        
        if (!sessionId) {
            sessionId = this.generateUUID();
        }
        
        sessionStorage.setItem('canagent_session_id', sessionId);
        this.updateActivity();
        
        return sessionId;
    }
    
    updateActivity() {
        this.lastActivity = Date.now();
        sessionStorage.setItem('canagent_last_activity', this.lastActivity.toString());
    }
    
    reset() {
        // Soft reset - —Å–æ—Ö—Ä–∞–Ω—è–µ–º ID –Ω–æ –æ—á–∏—â–∞–µ–º –∫–æ–Ω—Ç–µ–∫—Å—Ç
        sessionStorage.setItem('canagent_session_id', this.generateUUID());
        this.updateActivity();
        this.isRestored = false;
    }
}
```

### 2. Intelligent API Client

```javascript
// api-client.js - –ö–ª–∏–µ–Ω—Ç —Å –æ–±—Ä–∞–±–æ—Ç–∫–æ–π fallback

class IntelligentAPIClient {
    constructor(sessionManager) {
        this.sessionManager = sessionManager;
        this.baseUrl = '/api/v1/chat';
        this.retryAttempts = 2;
    }
    
    async sendMessage(message) {
        let attempts = 0;
        
        while (attempts < this.retryAttempts) {
            try {
                const response = await this.makeRequest(message);
                
                // –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤
                this.handleResponseIndicators(response);
                
                return response;
                
            } catch (error) {
                attempts++;
                
                if (attempts >= this.retryAttempts) {
                    // –ü–æ–∫–∞–∑–∞—Ç—å offline fallback
                    return this.getOfflineFallback(message);
                }
                
                // –ñ–¥–µ–º –ø–µ—Ä–µ–¥ –ø–æ–≤—Ç–æ—Ä–æ–º
                await this.delay(1000 * attempts);
            }
        }
    }
    
    async makeRequest(message) {
        const response = await fetch(`${this.baseUrl}/ask/`, {
            method: 'POST',
            headers: {'Content-Type': 'application/json'},
            body: JSON.stringify({
                message: message,
                session_id: this.sessionManager.sessionId,
                history: this.getRecentHistory(),
                source_platform: window.location.hostname
            })
        });
        
        if (!response.ok) {
            throw new Error(`API Error: ${response.status}`);
        }
        
        return await response.json();
    }
    
    handleResponseIndicators(response) {
        // –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä–æ–≤ —Å–æ—Å—Ç–æ—è–Ω–∏—è
        if (response.is_restored) {
            this.showNotification('Sesi√≥n restaurada / Session restored');
        }
        
        if (response.is_fallback) {
            this.showNotification('Modo offline / Offline mode');
        }
        
        if (response.confidence < 0.5) {
            this.showConfidenceWarning(response.confidence);
        }
        
        // –û–±–Ω–æ–≤–ª–µ–Ω–∏–µ session
        if (response.session_id) {
            this.sessionManager.sessionId = response.session_id;
        }
        
        if (response.language) {
            this.sessionManager.language = response.language;
        }
    }
    
    getOfflineFallback(message) {
        // –ë–∞–∑–æ–≤—ã–π offline –æ—Ç–≤–µ—Ç
        const lang = this.detectLocalLanguage(message);
        
        return {
            response: lang === 'es' 
                ? "Lo siento, hay problemas de conexi√≥n. Intenta de nuevo."
                : "Sorry, connection issues. Please try again.",
            recommended_strains: [],
            query_type: 'error',
            confidence: 0,
            is_offline: true,
            quick_actions: [
                lang === 'es' ? "Reintentar" : "Retry",
                lang === 'es' ? "Nueva b√∫squeda" : "New search"
            ]
        };
    }
    
    detectLocalLanguage(text) {
        // –ü—Ä–æ—Å—Ç–∞—è –¥–µ—Ç–µ–∫—Ü–∏—è —è–∑—ã–∫–∞ –Ω–∞ –∫–ª–∏–µ–Ω—Ç–µ
        const spanishWords = ['para', 'necesito', 'quiero', 'cu√°l'];
        const hasSpanish = spanishWords.some(word => 
            text.toLowerCase().includes(word)
        );
        return hasSpanish ? 'es' : 'en';
    }
}
```

### 3. Adaptive UI

```javascript
// ui-adapter.js - –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π UI

class AdaptiveUI {
    constructor(apiClient) {
        this.apiClient = apiClient;
        this.currentStrains = [];
    }
    
    async handleUserMessage(message) {
        // –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä –∑–∞–≥—Ä—É–∑–∫–∏
        this.showLoading();
        
        // –û—Ç–ø—Ä–∞–≤–∫–∞ —Å–æ–æ–±—â–µ–Ω–∏—è
        const response = await this.apiClient.sendMessage(message);
        
        // –°–∫—Ä—ã—Ç—å –∑–∞–≥—Ä—É–∑–∫—É
        this.hideLoading();
        
        // –ê–¥–∞–ø—Ç–∏–≤–Ω—ã–π —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥
        this.renderAdaptive(response);
    }
    
    renderAdaptive(response) {
        // –°–æ—Ö—Ä–∞–Ω–∏—Ç—å —Ç–µ–∫—É—â–∏–µ —Å–æ—Ä—Ç–∞
        if (response.recommended_strains.length > 0) {
            this.currentStrains = response.recommended_strains;
        }
        
        // –í—ã–±–æ—Ä –º–µ—Ç–æ–¥–∞ —Ä–µ–Ω–¥–µ—Ä–∏–Ω–≥–∞ –ø–æ —Ç–∏–ø—É
        const renderers = {
            'follow_up': () => this.renderFollowUp(response),
            'comparison': () => this.renderComparison(response),
            'clarification': () => this.renderClarification(response),
            'no_context': () => this.renderNoContext(response),
            'reset': () => this.renderReset(response),
            'error': () => this.renderError(response),
            'new_search': () => this.renderNewSearch(response)
        };
        
        const renderer = renderers[response.query_type] || renderers['new_search'];
        renderer();
        
        // –ü–æ–∫–∞–∑–∞—Ç—å quick actions
        if (response.quick_actions && response.quick_actions.length > 0) {
            this.renderQuickActions(response.quick_actions);
        }
        
        // –ü–æ–∫–∞–∑–∞—Ç—å –∏–Ω–¥–∏–∫–∞—Ç–æ—Ä—ã –∫–∞—á–µ—Å—Ç–≤–∞
        this.showQualityIndicators(response);
    }
    
    renderQuickActions(actions) {
        const container = document.getElementById('quick-actions');
        
        container.innerHTML = actions.map(action => `
            <button 
                class="quick-action-btn" 
                onclick="handleQuickAction('${this.escapeHtml(action)}')"
            >
                ${this.escapeHtml(action)}
            </button>
        `).join('');
        
        // –ê–Ω–∏–º–∞—Ü–∏—è –ø–æ—è–≤–ª–µ–Ω–∏—è
        container.classList.add('fade-in');
    }
    
    renderNoContext(response) {
        // –°–ø–µ—Ü–∏–∞–ª—å–Ω—ã–π UI –¥–ª—è –æ—Ç—Å—É—Ç—Å—Ç–≤–∏—è –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
        this.showMessage(
            response.response,
            'warning',
            {
                icon: '‚ö†Ô∏è',
                suggestions: true
            }
        );
    }
    
    renderClarification(response) {
        // UI –¥–ª—è —É—Ç–æ—á–Ω–µ–Ω–∏–π
        this.showMessage(
            response.response,
            'info',
            {
                icon: '‚ùì',
                highlight_actions: true
            }
        );
    }
    
    showQualityIndicators(response) {
        const indicators = [];
        
        if (response.is_restored) {
            indicators.push({
                type: 'info',
                text: 'Sesi√≥n restaurada'
            });
        }
        
        if (response.is_fallback) {
            indicators.push({
                type: 'warning',
                text: 'Modo b√°sico'
            });
        }
        
        if (response.confidence < 0.7) {
            indicators.push({
                type: 'caution',
                text: `Confianza: ${Math.round(response.confidence * 100)}%`
            });
        }
        
        this.renderIndicators(indicators);
    }
}
```

---

## üìä –î–∏–∞–≥—Ä–∞–º–º–∞ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–æ–≥–æ –ø–æ—Ç–æ–∫–∞

```mermaid
graph TD
    A[User Query] --> B[Session Manager]
    B --> C{Session Valid?}
    C -->|No/Expired| D[Restore/Create Session]
    C -->|Yes| E[Load Session]
    D --> F[Unified LLM Processor]
    E --> F
    F --> G{LLM Available?}
    G -->|No| H[Fallback Analyzer]
    G -->|Yes| I[Single LLM Call]
    H --> J[Rule-based Analysis]
    I --> K[Complete Analysis]
    J --> K
    K --> L{Has Context Issues?}
    L -->|No Context| M[Handle No Context]
    L -->|Conflicts| N[Resolve Conflicts]
    L -->|OK| O[Process by Type]
    M --> P[Generate Response]
    N --> O
    O --> Q{Use Embeddings?}
    Q -->|Yes| R[Check Cache]
    Q -->|No| S[Quick Filters]
    R --> T{In Cache?}
    T -->|Yes| U[Use Cached]
    T -->|No| V[Generate & Cache]
    U --> S
    V --> S
    S --> P
    P --> W[Return Response]
```

---

## ‚öôÔ∏è –ö–æ–Ω—Ñ–∏–≥—É—Ä–∞—Ü–∏—è –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

```env
# LLM Optimization
UNIFIED_LLM_TIMEOUT=3000          # 3 sec timeout
FALLBACK_ON_TIMEOUT=true          # Use rules if timeout
LLM_RETRY_ATTEMPTS=1              # Only 1 retry

# Caching
EMBEDDING_CACHE_TTL=86400         # 24 hours for strains
QUERY_EMBEDDING_CACHE_TTL=3600    # 1 hour for queries
CRITERIA_CACHE_TTL=300            # 5 min for criteria

# Session Management  
SESSION_TTL_HOURS=4               # Active session
SESSION_BACKUP_DAYS=7             # Preference backup
SESSION_RESTORE_ENABLED=true      # Allow restoration

# Performance
MAX_STRAINS_IN_MEMORY=20
MAX_CONVERSATION_HISTORY=50
SEMANTIC_SEARCH_THRESHOLD=0.7
MIN_CONFIDENCE_FOR_ACTION=0.3

# Monitoring
ENABLE_PERFORMANCE_METRICS=true
LOG_SLOW_QUERIES=true
SLOW_QUERY_THRESHOLD_MS=2000
```



## ‚úÖ –†–µ—à–µ–Ω–Ω—ã–µ –ø—Ä–æ–±–ª–µ–º—ã

1. ‚úÖ **–ï–¥–∏–Ω—ã–π LLM –≤—ã–∑–æ–≤** - –≤—Å–µ –æ–ø–µ—Ä–∞—Ü–∏–∏ –≤ –æ–¥–Ω–æ–º –∑–∞–ø—Ä–æ—Å–µ
2. ‚úÖ **Fallback –º–µ—Ö–∞–Ω–∏–∑–º** - —Ä–∞–±–æ—Ç–∞–µ—Ç –¥–∞–∂–µ –±–µ–∑ OpenAI
3. ‚úÖ **Edge cases** - –æ–±—Ä–∞–±–æ—Ç–∫–∞ "–∫–∞–∫–æ–π –ª—É—á—à–µ?" –±–µ–∑ –∫–æ–Ω—Ç–µ–∫—Å—Ç–∞
4. ‚úÖ **–ö–µ—à–∏—Ä–æ–≤–∞–Ω–∏–µ embeddings** - 80% —ç–∫–æ–Ω–æ–º–∏—è –Ω–∞ –ø–æ–≤—Ç–æ—Ä–Ω—ã—Ö
5. ‚úÖ **–î–µ—Ç–µ–∫—Ü–∏—è —Å–º–µ–Ω—ã —Ç–µ–º—ã** - –ø–æ–Ω–∏–º–∞–µ—Ç –ø–µ—Ä–µ—Ö–æ–¥—ã
6. ‚úÖ **Session restoration** - –≤–æ—Å—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∏–µ –ø–æ—Å–ª–µ –∏—Å—Ç–µ—á–µ–Ω–∏—è
7. ‚úÖ **–î–∏–Ω–∞–º–∏—á–µ—Å–∫–∏–µ quick actions** - –≥–µ–Ω–µ—Ä–∏—Ä—É—é—Ç—Å—è –ø–æ –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
8. ‚úÖ **–ú–µ—Ö–∞–Ω–∏–∑–º reset** - "empezar de nuevo" —Ä–∞–±–æ—Ç–∞–µ—Ç
9. ‚úÖ **–ö–æ–Ω—Ñ–ª–∏–∫—Ç—ã –∫—Ä–∏—Ç–µ—Ä–∏–µ–≤** - –æ–±–Ω–∞—Ä—É–∂–µ–Ω–∏–µ –∏ —Ä–∞–∑—Ä–µ—à–µ–Ω–∏–µ
10. ‚úÖ **Performance** - —Å–Ω–∏–∂–µ–Ω–∏–µ latency –≤ 3-4 —Ä–∞–∑–∞


